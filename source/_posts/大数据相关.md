---
title: 大数据相关
date: 2019-11-24 16:48:37
tags: BigData
categories: BigData
---

重点参考：

- https://github.com/CheckChe0803/BigData-Interview

<table>
    <tr>
     <th><img width="50px" src="大数据相关/hadoop.jpg"></th>
     <th><img width="50px" src="大数据相关/hive.jpg"></th>
     <th><img width="50px" src="大数据相关/spark.jpg"></th>
     <th><img width="50px" src="大数据相关/flink.png"></th>
     <th><img width="50px" src="大数据相关/hbase.png"></th>
     <th><img width="50px" src="大数据相关/kafka.png"></th>
     <th><img width="50px" src="大数据相关/zookeeper.jpg"></th>
    </tr>
<tr>
  <td align="center">Hadoop</td>
  <td align="center">Hive</td>
  <td align="center">Spark</td>
  <td align="center">Flink</td>
  <td align="center">HBase</td>
  <td align="center">Kafka</td>
  <td align="center">Zookeeper</td>
</tr>
 <tr>
     <td align="center"><a href="https://hadoop.apache.org/docs/">文档</a></td>
  <td align="center"><a href="https://hive.apache.org/">文档</a></td>
  <td align="center"><a href="https://spark.apache.org/docs/">文档</a></td>
  <td align="center"><a href="https://ci.apache.org/projects/flink/flink-docs-stable/">文档</a></td>
  <td align="center"><a href="https://hbase.apache.org/book.html">文档</a></td>
  <td align="center"><a href="https://kafka.apache.org/documentation/">文档</a></td>
  <td align="center"><a href="https://zookeeper.apache.org/">文档</a></td>
</tr>
</table>

<!--more-->

## Hadoop

### [HDFS架构？](https://hadoop.apache.org/docs/)[^2]

#### [HDFS1](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html)

- 架构图

> HDFS has a master/slave architecture. An HDFS cluster consists of a single NameNode, a master server that manages the file system namespace and regulates access to files by clients. In addition, there are a number of DataNodes, usually one per node in the cluster, which manage storage attached to the nodes that they run on. HDFS exposes a file system namespace and allows user data to be stored in files. Internally, a file is split into one or more blocks and these blocks are stored in a set of DataNodes. The NameNode executes file system namespace operations like opening, closing, and renaming files and directories. It also determines the mapping of blocks to DataNodes. The DataNodes are responsible for serving read and write requests from the file system’s clients. The DataNodes also perform block creation, deletion, and replication upon instruction from the NameNode.

![](大数据相关/hdfs1architecture.gif)

- [x] NameNode

NameNode 负责管理整个分布式系统的元数据，主要包括：

 - 目录树结构；
 - 文件到数据库 Block 的映射关系；

- Block 副本及其存储位置等管理数据；
- DataNode 的状态监控，两者通过段时间间隔的心跳来传递管理信息和数据信息，通过这种方式的信息传递，NameNode 可以获知每个 DataNode 保存的 Block 信息、DataNode 的健康状况、命令 DataNode 启动停止等（如果发现某个 DataNode 节点故障，NameNode 会将其负责的 block 在其他 DataNode 上进行备份）。

这些数据保存在内存中，同时在磁盘保存两个元数据管理文件：fsimage 和 editlog。

- fsimage：是内存命名空间元数据在外存的镜像文件；
- editlog：则是各种元数据操作的 write-ahead-log 文件，在体现到内存数据变化前首先会将操作记入 editlog 中，以防止数据丢失。

这两个文件相结合可以构造完整的内存数据。

- [x] Secondary NameNode

Secondary NameNode 并不是 NameNode 的热备机，而是定期从 NameNode 拉取 fsimage 和 editlog 文件，并对两个文件进行合并，形成新的 fsimage 文件并传回 NameNode，这样做的目的是减轻 NameNod 的工作压力，本质上 SNN 是一个提供检查点功能服务的服务点。

- [x] DataNode

负责数据块的实际存储和读写工作，Block 默认是64MB（HDFS2.0改成了128MB），当客户端上传一个大文件时，HDFS 会自动将其切割成固定大小的 Block，为了保证数据可用性，每个 Block 会以多备份的形式存储，默认是3份。

#### [HDFS2](https://hadoop.apache.org/docs/r2.10.0/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)

- 架构图和上面一样
- [HDFS High Availability]()

![](大数据相关/hdfs-ha.png)

| 属性                                                         |
| ------------------------------------------------------------ |
| **（1）Active NameNode 和 Standby NameNode**：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务； |
| **（2）ZKFailoverController**（主备切换控制器，FC）：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换（当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换）； |
| **（3）Zookeeper 集群**：为主备切换控制器提供主备选举支持；  |
| **（4）共享存储系统**：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备 NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在**确认元数据完全同步之后才能继续对外提供服务**。 |
| **（5）DataNode 节点**：因为主 NameNode 和备 NameNode 需要共享 HDFS 的数据块和 DataNode 之间的映射关系，为了使故障切换能够快速进行，DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。 |

### HDFS[比较](https://cwiki.apache.org/confluence/display/HADOOP2/Roadmap)（主要体现在jdk版本，HA等）

| 比较   | 特性                          |
| ------ | ----------------------------- |
| HDFS 1 |                               |
| HDFS 2 | HADOOP，HDFS，YARN，MAPREDUCE |
| HDFS 3 | Move to JDK8+                 |



### HDFS相关的例子？

- 常用命令

```
查看文件系统的基本信息和统计信息：hdfs dfsadmin -report
建立文件夹: hadoop fs -mkdir /user/tpc-h1G
上传文件:hadoop fs -put *.tbl /user/tpc-h1G
```



### Yarn架构？（资源管理）[^1]

> The fundamental idea of YARN is to split up the functionalities of resource management and job scheduling/monitoring into separate daemons. The idea is to have a global ResourceManager (*RM*) and per-application ApplicationMaster (*AM*). An application is either a single job or a DAG of jobs.

- Yarn架构图

![](https://hadoop.apache.org/docs/r3.2.1/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif)

### MapReduce过程？

### Yarn 调度MapReduce？

### hdfs写流程？

### hdfs读流程？

### hdfs创建一个文件的流程？

### hadoop1.x 和hadoop 2.x 的区别？

### hadoop1.x的缺点？

### hadoop HA介绍？

### hadoop的常用配置文件有哪些,自己实际改过哪些？

### 小文件过多会有什么危害,如何避免？

### 启动hadoop集群会分别启动哪些进程,各自的作用？



## HIVE

### hive 内部表和外部表的区别？

### Hive中 sort by / order by / cluster by / distribute by 的区别？

### hive的metastore的三种模式？

### hive 中 join都有哪些]？

### Impala 和 hive 的查询有哪些区别](./docs/Impala和hive的查询有哪些区别.md)

### Hive中大表join小表的优化方法]？

### Hive Sql 是怎样解析成MR job的?

### Hive UDF简单介绍？

### SQL题: 按照学生科目分组, 取每个科目的TopN？

### SQL题: 获取每个用户的前1/4次的数据？







## Spark

### spark 的运行架构？

### 一个spark程序的执行流程？

### spark的shuffle介绍？

### Spark的 partitioner 都有哪些?

### spark 有哪几种join？

### RDD有哪些特点？

### 讲一下宽依赖和窄依赖？

### Spark中的算子都有哪些？

### RDD的缓存级别都有哪些？

### RDD 懒加载是什么意思？

### 讲一下spark的几种部署方式？

### spark on yarn 模式下的 cluster模式和 client模式有什么区别？

### spark运行原理,从提交一个jar到最后返回结果,整个过程？

### spark的stage是如何划分的？

### spark的rpc: spark2.0为什么放弃了akka 而用netty？

### spark的各种HA,  master/worker/executor/driver/task的ha？

### spark的内存管理机制,spark 1.6前后分析对比, spark2.0 做出来哪些优化？

### 讲一下spark 中的广播变量？

### 什么是数据倾斜,怎样去处理数据倾斜？

### 分析一下一段spark代码中哪些部分在Driver端执行,哪些部分在Worker端执行？



## Flink

### 讲一下flink的运行架构？

### 讲一下flink的作业执行流程？

### flink具体是如何实现exactly once 语义？

### flink 的 window 实现机制？

### flink的window分类？

### flink 的 state 是存储在哪里的？

### flink是如何实现反压的？

### flink的部署模式都有哪些？

### 讲一下flink on yarn的部署？

### flink中的时间概念 , eventTime 和 processTime的区别？

### flink中的session Window怎样使用？

### flink中的session Window怎样使用









## HBase

### 讲一下 Hbase 架构？

### hbase 如何设计 rowkey？

### 讲一下hbase的存储结构,这样的存储结构有什么优缺点？

### hbase的HA实现,zookeeper在其中的作用？

### HMaster宕机的时候,哪些操作还能正常工作？

### 讲一下hbase的写数据的流程？

### 讲一下hbase读数据的流程？









## Kafka

### 讲一下 kafka 的架构？

### kafka 与其他消息组件对比？

### kafka 实现高吞吐的原理？

### kafka怎样保证不重复消费？

### kafka怎样保证不丢失消息？

### kafka 与 spark streaming 集成,如何保证 exactly once 语义？

### ack 有哪几种, 生产中怎样选择？

### 如何通过 offset 寻找数据？

### 如何清理过期数据？

### 1条message中包含哪些信息？

### 讲一下zookeeper在kafka中的作用？

### kafka 可以脱离 zookeeper 单独使用吗？

### kafka有几种数据保留策略？

### kafka同时设置了7天和10G清除数据,到第5天的时候消息到达了10G,这个时候kafka如何处理？



## Zookeeper

### zookeeper是什么,都有哪些功能？

### zk 有几种部署模式？

### zk 是怎样保证主从节点的状态同步？

### 说一下 zk 的通知机制？

### zk 的分布式锁实现方式？

### zk 采用的哪种分布式一致性协议? 还有哪些分布式一致性协议？

### 讲一下leader 选举过程？



## 引用

[^1]:Vinod  Kumar Vavilapalli, Arun C. Murthy, Chris Douglas, Sharad Agarwal, &  Eric Baldeschwieler. (2013). Apache Hadoop YARN: yet another resource  negotiator. *Proceedings of the 4th annual Symposium on Cloud Computing*. ACM.
[^2]: https://hadoop.apache.org/docs/

