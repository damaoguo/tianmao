---
title: 大数据相关
date: 2019-11-24 16:48:37
tags: BigData
categories: BigData
---

重点参考：

- https://github.com/CheckChe0803/BigData-Interview

<table>
    <tr>
     <th><img width="50px" src="大数据相关/hadoop.jpg"></th>
     <th><img width="50px" src="大数据相关/hive.jpg"></th>
     <th><img width="50px" src="大数据相关/spark.jpg"></th>
     <th><img width="50px" src="大数据相关/flink.png"></th>
     <th><img width="50px" src="大数据相关/hbase.png"></th>
     <th><img width="50px" src="大数据相关/kafka.png"></th>
     <th><img width="50px" src="大数据相关/zookeeper.jpg"></th>
    </tr>
<tr>
  <td align="center">Hadoop</td>
  <td align="center">Hive</td>
  <td align="center">Spark</td>
  <td align="center">Flink</td>
  <td align="center">HBase</td>
  <td align="center">Kafka</td>
  <td align="center">Zookeeper</td>
</tr>
 <tr>
     <td align="center"><a href="https://hadoop.apache.org/docs/">文档</a></td>
  <td align="center"><a href="https://hive.apache.org/">文档</a></td>
  <td align="center"><a href="https://spark.apache.org/docs/">文档</a></td>
  <td align="center"><a href="https://ci.apache.org/projects/flink/flink-docs-stable/">文档</a></td>
  <td align="center"><a href="https://hbase.apache.org/book.html">文档</a></td>
  <td align="center"><a href="https://kafka.apache.org/documentation/">文档</a></td>
  <td align="center"><a href="https://zookeeper.apache.org/">文档</a></td>
</tr>
</table>

<!--more-->

## Hadoop

### [HDFS架构？](https://hadoop.apache.org/docs/)[^2]

#### [HDFS1](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html)

- 架构图

> HDFS has a master/slave architecture. An HDFS cluster consists of a single NameNode, a master server that manages the file system namespace and regulates access to files by clients. In addition, there are a number of DataNodes, usually one per node in the cluster, which manage storage attached to the nodes that they run on. HDFS exposes a file system namespace and allows user data to be stored in files. Internally, a file is split into one or more blocks and these blocks are stored in a set of DataNodes. The NameNode executes file system namespace operations like opening, closing, and renaming files and directories. It also determines the mapping of blocks to DataNodes. The DataNodes are responsible for serving read and write requests from the file system’s clients. The DataNodes also perform block creation, deletion, and replication upon instruction from the NameNode.

![](大数据相关/hdfs1architecture.gif)

- [x] NameNode

NameNode 负责管理整个分布式系统的元数据，主要包括：

 - 目录树结构；
 - 文件到数据库 Block 的映射关系；

- Block 副本及其存储位置等管理数据；
- DataNode 的状态监控，两者通过段时间间隔的心跳来传递管理信息和数据信息，通过这种方式的信息传递，NameNode 可以获知每个 DataNode 保存的 Block 信息、DataNode 的健康状况、命令 DataNode 启动停止等（如果发现某个 DataNode 节点故障，NameNode 会将其负责的 block 在其他 DataNode 上进行备份）。

这些数据保存在内存中，同时在磁盘保存两个元数据管理文件：fsimage 和 editlog。

- fsimage：是内存命名空间元数据在外存的镜像文件；
- editlog：则是各种元数据操作的 write-ahead-log 文件，在体现到内存数据变化前首先会将操作记入 editlog 中，以防止数据丢失。

这两个文件相结合可以构造完整的内存数据。

- [x] Secondary NameNode

Secondary NameNode 并不是 NameNode 的热备机，而是定期从 NameNode 拉取 fsimage 和 editlog 文件，并对两个文件进行合并，形成新的 fsimage 文件并传回 NameNode，这样做的目的是减轻 NameNod 的工作压力，本质上 SNN 是一个提供检查点功能服务的服务点。

- [x] DataNode

负责数据块的实际存储和读写工作，Block 默认是64MB（HDFS2.0改成了128MB），当客户端上传一个大文件时，HDFS 会自动将其切割成固定大小的 Block，为了保证数据可用性，每个 Block 会以多备份的形式存储，默认是3份。

#### [HDFS2](https://hadoop.apache.org/docs/r2.10.0/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)

- 架构图和上面一样
- [HDFS High Availability]()

![](大数据相关/hdfs-ha.png)

| 属性                                                         |
| ------------------------------------------------------------ |
| **（1）Active NameNode 和 Standby NameNode**：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务； |
| **（2）ZKFailoverController**（主备切换控制器，FC）：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换（当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换）； |
| **（3）Zookeeper 集群**：为主备切换控制器提供主备选举支持；  |
| **（4）共享存储系统**：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备 NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在**确认元数据完全同步之后才能继续对外提供服务**。 |
| **（5）DataNode 节点**：因为主 NameNode 和备 NameNode 需要共享 HDFS 的数据块和 DataNode 之间的映射关系，为了使故障切换能够快速进行，DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。 |

### HDFS[比较](https://cwiki.apache.org/confluence/display/HADOOP2/Roadmap)（主要体现在jdk版本，HA等）

| 比较   | 特性                          |
| ------ | ----------------------------- |
| HDFS 1 |                               |
| HDFS 2 | HADOOP，HDFS，YARN，MAPREDUCE |
| HDFS 3 | Move to JDK8+                 |



### HDFS相关的例子？

- 常用命令

```
查看文件系统的基本信息和统计信息：hdfs dfsadmin -report
建立文件夹: hadoop fs -mkdir /user/tpc-h1G
上传文件:hadoop fs -put *.tbl /user/tpc-h1G
```



### Yarn架构？（资源管理）[^3]

> The fundamental idea of YARN is to split up the functionalities of resource management and job scheduling/monitoring into separate daemons. The idea is to have a global ResourceManager (*RM*) and per-application ApplicationMaster (*AM*). An application is either a single job or a DAG of jobs.

- 原理[^1]
- Yarn架构图

![](https://hadoop.apache.org/docs/r3.2.1/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif)

#### ResourceManager（RM）

RM 是一个全局的资源管理器，负责整个系统的资源管理和分配，它主要有两个组件构成：

- 调度器 Scheduler

调度器根据容量、队列等限制条件（如某个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。要注意的是，该调度器是一个纯调度器，它不再从事任何与应用程序有关的工作，比如不负责重新启动（因应用程序失败或者硬件故障导致的失败），这些均交由应用程序相关的 ApplicationMaster 完成。调度器仅根据各个应用程序的资源需求进行资源分配，而资源分配单位用一个抽象概念 **资源容器(Resource Container，也即 Container)**，Container 是一个动态资源分配单位，它将内存、CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需求设计新的调度器，YARN 提供了多种直接可用的调度器，比如 Fair Scheduler 和 Capacity Schedule 等。

- 应用程序管理器 Applications Manager，ASM。

应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以 AM、监控 AM 运行状态并在失败时重新启动它等。

#### NodeManager（NM）

NM 是每个节点上运行的资源和任务管理器，一方面，它会定时向 RM 汇报本节点上的资源使用情况和各个 Container 的运行状态；另一方面，它接收并处理来自 AM 的 Container 启动/停止等各种请求。

#### ApplicationMaster（AM）

提交的每个作业都会包含一个 AM，主要功能包括：

- 与 RM 协商以获取资源（用 container 表示）；

- 将得到的任务进一步分配给内部的任务；

- 与 NM 通信以启动/停止任务；

- 监控所有任务的运行状态，当任务有失败时，重新为任务申请资源并重启任务。

MapReduce 就是原生支持 ON YARN 的一种框架，可以在 YARN 上运行 MapReduce 作业。有很多分布式应用都开发了对应的应用程序框架，用于在 YARN 上运行任务，例如 Spark，Storm、Flink 等。

#### Container

Container 是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当 AM 向 RM 申请资源时，RM 为 AM 返回的资源便是用 Container 表示的。 YARN 会为每个任务分配一个 Container 且该任务只能使用该 Container 中描述的资源。

### MapReduce过程？

MapReduce分为两个阶段: **Map** 和  **Ruduce**.

#### **Map阶段:**

- **input**.

 在进行map计算之前，mapreduce会根据输入文件计算输入分片（input split），每个输入分片（input split）针对一个map任务

- **map**

就是程序员编写好的map函数了，因此map函数效率相对好控制，而且一般map操作都是本地化操作也就是在数据存储节点上进行 

- **Partition**. 

需要计算每一个map的结果需要发到哪个reduce端,partition数等于reducer数.默认采用HashPartition.

- **spill**

此阶段分为sort和combine.首先分区过得数据会经过排序之后写入环形内存缓冲区.在达到阈值之后守护线程将数据溢出分区文件.

- **sort** 

在写入环形缓冲区前,对数据排序.<key,value,partition>格式排序

- **combine**(可选). 

在溢出文件之前,提前开始combine,相当于本地化的reduce操作

- **merge** 

spill结果会有很多个文件,但最终输出只有一个,故有一个merge操作会合并所有的本地文件,并且该文件会有一个对应的索引文件.

#### **Reduce阶段:**

- **copy**.

拉取数据,reduce启动数据copy线程(默认5个),通过Http请求对应节点的map task输出文件,copy的数据也会先放到内部缓冲区.之后再溢写,类似map端操作.

- **merge**

 合并多个copy的多个map端的数据.在一个reduce端先将多个map端的数据溢写到本地磁盘,之后再将多个文件合并成一个文件.  数据经过 **内存->磁盘 , 磁盘->磁盘**的过程.

- **output**

merge阶段最后会生成一个文件,将此文件转移到内存中,shuffle阶段结束

- **reduce**

开始执行reduce任务,最后结果保留在hdfs上.

#### 案例[^4]

下表是一个不同年份的用电量，找出平均用电量最大的年份

| Jan  | Feb  | Mar  | Apr  | May  | Jun  | Jul  | Aug  | Sep  | Oct  | Nov  | Dec  | Avg  |      |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 1979 | 23   | 23   | 2    | 43   | 24   | 25   | 26   | 26   | 26   | 26   | 25   | 26   | 25   |
| 1980 | 26   | 27   | 28   | 28   | 28   | 30   | 31   | 31   | 31   | 30   | 30   | 30   | 29   |
| 1981 | 31   | 32   | 32   | 32   | 33   | 34   | 35   | 36   | 36   | 34   | 34   | 34   | 34   |
| 1984 | 39   | 38   | 39   | 39   | 39   | 41   | 42   | 43   | 40   | 39   | 38   | 38   | 40   |
| 1985 | 38   | 39   | 39   | 39   | 39   | 41   | 41   | 41   | 00   | 40   | 39   | 39   | 45   |

分别实现Mapper和Reducer接口。

```java
package hadoop; 

import java.util.*; 

import java.io.IOException; 
import java.io.IOException; 

import org.apache.hadoop.fs.Path; 
import org.apache.hadoop.conf.*; 
import org.apache.hadoop.io.*; 
import org.apache.hadoop.mapred.*; 
import org.apache.hadoop.util.*; 

public class ProcessUnits {
   //Mapper class 
   public static class E_EMapper extends MapReduceBase implements 
   Mapper<LongWritable ,/*Input key Type */ 
   Text,                /*Input value Type*/ 
   Text,                /*Output key Type*/ 
   IntWritable>        /*Output value Type*/ 
   {
      //Map function 
      public void map(LongWritable key, Text value, 
      OutputCollector<Text, IntWritable> output,   
      
      Reporter reporter) throws IOException { 
         String line = value.toString(); 
         String lasttoken = null; 
         StringTokenizer s = new StringTokenizer(line,"\t"); 
         String year = s.nextToken(); 
         
         while(s.hasMoreTokens()) {
            lasttoken = s.nextToken();
         }
         int avgprice = Integer.parseInt(lasttoken); 
         output.collect(new Text(year), new IntWritable(avgprice)); 
      } 
   }
   
   //Reducer class 
   public static class E_EReduce extends MapReduceBase implements Reducer< Text, IntWritable, Text, IntWritable > {
   
      //Reduce function 
      public void reduce( Text key, Iterator <IntWritable> values, 
      OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException { 
         int maxavg = 30; 
         int val = Integer.MIN_VALUE; 
            
         while (values.hasNext()) { 
            if((val = values.next().get())>maxavg) { 
               output.collect(key, new IntWritable(val)); 
            } 
         }
      } 
   }

   //Main function 
   public static void main(String args[])throws Exception { 
      JobConf conf = new JobConf(ProcessUnits.class); 
      
      conf.setJobName("max_eletricityunits"); 
      conf.setOutputKeyClass(Text.class);
      conf.setOutputValueClass(IntWritable.class); 
      conf.setMapperClass(E_EMapper.class); 
      conf.setCombinerClass(E_EReduce.class); 
      conf.setReducerClass(E_EReduce.class); 
      conf.setInputFormat(TextInputFormat.class); 
      conf.setOutputFormat(TextOutputFormat.class); 
      
      FileInputFormat.setInputPaths(conf, new Path(args[0])); 
      FileOutputFormat.setOutputPath(conf, new Path(args[1])); 
      
      JobClient.runJob(conf); 
   } 
} 
```

### Yarn 调度MapReduce？

Yarn采用的双层调度框架，RM将资源分配给AM,AM再将资源进一步分配给Task,资源不够时会为TASK预留，直到资源充足。

### hdfs写流程？

### hdfs读流程？

### hdfs创建一个文件的流程？

### hadoop1.x 和hadoop 2.x 的区别？

### hadoop1.x的缺点？

### hadoop HA介绍？

### hadoop的常用配置文件有哪些,自己实际改过哪些？

### 小文件过多会有什么危害,如何避免？

### 启动hadoop集群会分别启动哪些进程,各自的作用？



## HIVE

### hive 内部表和外部表的区别？

### Hive中 sort by / order by / cluster by / distribute by 的区别？

### hive的metastore的三种模式？

### hive 中 join都有哪些]？

### Impala 和 hive 的查询有哪些区别](./docs/Impala和hive的查询有哪些区别.md)

### Hive中大表join小表的优化方法]？

### Hive Sql 是怎样解析成MR job的?

### Hive UDF简单介绍？

### SQL题: 按照学生科目分组, 取每个科目的TopN？

### SQL题: 获取每个用户的前1/4次的数据？







## Spark

### spark 的运行架构？

### 一个spark程序的执行流程？

### spark的shuffle介绍？

### Spark的 partitioner 都有哪些?

### spark 有哪几种join？

### RDD有哪些特点？

### 讲一下宽依赖和窄依赖？

### Spark中的算子都有哪些？

### RDD的缓存级别都有哪些？

### RDD 懒加载是什么意思？

### 讲一下spark的几种部署方式？

### spark on yarn 模式下的 cluster模式和 client模式有什么区别？

### spark运行原理,从提交一个jar到最后返回结果,整个过程？

### spark的stage是如何划分的？

### spark的rpc: spark2.0为什么放弃了akka 而用netty？

### spark的各种HA,  master/worker/executor/driver/task的ha？

### spark的内存管理机制,spark 1.6前后分析对比, spark2.0 做出来哪些优化？

### 讲一下spark 中的广播变量？

### 什么是数据倾斜,怎样去处理数据倾斜？

### 分析一下一段spark代码中哪些部分在Driver端执行,哪些部分在Worker端执行？



## Flink

### 讲一下flink的运行架构？

### 讲一下flink的作业执行流程？

### flink具体是如何实现exactly once 语义？

### flink 的 window 实现机制？

### flink的window分类？

### flink 的 state 是存储在哪里的？

### flink是如何实现反压的？

### flink的部署模式都有哪些？

### 讲一下flink on yarn的部署？

### flink中的时间概念 , eventTime 和 processTime的区别？

### flink中的session Window怎样使用？

### flink中的session Window怎样使用









## HBase

### 讲一下 Hbase 架构？

### hbase 如何设计 rowkey？

### 讲一下hbase的存储结构,这样的存储结构有什么优缺点？

### hbase的HA实现,zookeeper在其中的作用？

### HMaster宕机的时候,哪些操作还能正常工作？

### 讲一下hbase的写数据的流程？

### 讲一下hbase读数据的流程？









## Kafka

### 讲一下 kafka 的架构？

### kafka 与其他消息组件对比？

### kafka 实现高吞吐的原理？

### kafka怎样保证不重复消费？

### kafka怎样保证不丢失消息？

### kafka 与 spark streaming 集成,如何保证 exactly once 语义？

### ack 有哪几种, 生产中怎样选择？

### 如何通过 offset 寻找数据？

### 如何清理过期数据？

### 1条message中包含哪些信息？

### 讲一下zookeeper在kafka中的作用？

### kafka 可以脱离 zookeeper 单独使用吗？

### kafka有几种数据保留策略？

### kafka同时设置了7天和10G清除数据,到第5天的时候消息到达了10G,这个时候kafka如何处理？



## Zookeeper

### zookeeper是什么,都有哪些功能？

### zk 有几种部署模式？

### zk 是怎样保证主从节点的状态同步？

### 说一下 zk 的通知机制？

### zk 的分布式锁实现方式？

### zk 采用的哪种分布式一致性协议? 还有哪些分布式一致性协议？

### 讲一下leader 选举过程？



## 引用

[^1]:Vinod  Kumar Vavilapalli, Arun C. Murthy, Chris Douglas, Sharad Agarwal, &  Eric Baldeschwieler. (2013). Apache Hadoop YARN: yet another resource  negotiator. *Proceedings of the 4th annual Symposium on Cloud Computing*. ACM.
[^2]: https://hadoop.apache.org/docs/

[^3]: Vavilapalli, V. K., Murthy, A. C., Douglas, C., Agarwal, S., Konar, M., Evans, R., ... & Saha, B. (2013, October). Apache hadoop yarn: Yet another resource negotiator. In *Proceedings of the 4th annual Symposium on Cloud Computing* (p. 5). ACM.
[^4]: https://www.tutorialspoint.com/hadoop/hadoop_mapreduce.htm



